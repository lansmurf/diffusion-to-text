{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import T5EncoderModel\n",
    "import keyword\n",
    "import tokenize\n",
    "from io import StringIO\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def mask_tokens(code_snippet, language='python', mask_rate=0.15):\n",
    "    masked_code = []\n",
    "    if language == 'python':\n",
    "        # Tokenize the Python code snippet\n",
    "        tokens = list(tokenize.tokenize(StringIO(code_snippet).readline))\n",
    "        for tok in tokens:\n",
    "            # For keywords and identifiers (NAME tokens that aren't built-in functions), mask them based on mask_rate\n",
    "            if (tok.type == tokenize.NAME and (keyword.iskeyword(tok.string) or not tok.string.startswith('__'))) and random.random() < mask_rate:\n",
    "                masked_code.append('<MASK>')\n",
    "            else:\n",
    "                masked_code.append(tok.string)\n",
    "    elif language == 'bash':\n",
    "        # This is a placeholder: you'll need a more sophisticated method for Bash, possibly using regex\n",
    "        bash_keywords = ['if', 'else', 'fi', 'do', 'done', 'for', 'in', 'while', 'case', 'esac', 'echo', 'printf', 'export']\n",
    "        for word in code_snippet.split():\n",
    "            if word in bash_keywords and random.random() < mask_rate:\n",
    "                masked_code.append('<MASK>')\n",
    "            else:\n",
    "                masked_code.append(word)\n",
    "    return ' '.join(masked_code)\n",
    "\n",
    "\n",
    "def add_gaussian_noise(embeddings, mean=0.0, std=0.1):\n",
    "    noise = torch.randn_like(embeddings) * std + mean\n",
    "    return embeddings + noise\n",
    "    \n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward=2048, dropout=0.1):\n",
    "        super(Denoiser, self).__init__()\n",
    "        self.self_attn_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, \n",
    "                                       dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.cross_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        \n",
    "        # Noise prediction layer\n",
    "        self.noise_prediction_layer = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, noisy_embeddings, encoded_utterance=None, t=None, src_key_padding_mask=None):\n",
    "        # Self-attention layers\n",
    "        for layer in self.self_attn_layers:\n",
    "            noisy_embeddings = layer(noisy_embeddings, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # If encoded_utterance is provided, perform cross-attention\n",
    "        if encoded_utterance is not None:\n",
    "            attn_output, _ = self.cross_attn(noisy_embeddings, encoded_utterance, encoded_utterance)\n",
    "        else:\n",
    "            attn_output = noisy_embeddings\n",
    "\n",
    "        # Predict noise\n",
    "        predicted_noise = self.noise_prediction_layer(attn_output)\n",
    "        \n",
    "        # Remove predicted noise to get denoised embeddings\n",
    "        denoised_embeddings = attn_output - predicted_noise\n",
    "\n",
    "        return denoised_embeddings, predicted_noise\n",
    "\n",
    "class DecoderWithCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers=1, dim_feedforward=2048, dropout=0.1):\n",
    "        super(DecoderWithCrossAttention, self).__init__()\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, \n",
    "                                                   dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, denoised_embeddings, encoded_utterance=None):\n",
    "        if encoded_utterance is not None:\n",
    "            # Cross-attention in the decoder\n",
    "            output = self.transformer_decoder(denoised_embeddings, encoded_utterance)\n",
    "        else:\n",
    "            # If encoded_utterance is not provided, use dummy memory input\n",
    "            dummy_memory = torch.zeros_like(denoised_embeddings)  # Create dummy memory tensor\n",
    "            output = self.transformer_decoder(denoised_embeddings, memory=dummy_memory)\n",
    "        return output\n",
    "\n",
    "class CodeEmbeddingLayer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CodeEmbeddingLayer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, code_tokens):\n",
    "        # Convert code tokens to embeddings\n",
    "        return self.embedding(code_tokens)\n",
    "\n",
    "class T5EncoderBlock(nn.Module):\n",
    "    def __init__(self, model_name='t5-medium'):\n",
    "        super(T5EncoderBlock, self).__init__()\n",
    "        self.encoder = T5EncoderModel.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # Process input tokens through the T5 encoder\n",
    "        encoder_outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return encoder_outputs.last_hidden_state\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, vocab_size):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, vocab_size)\n",
    "        # Note: Softmax is not applied here as it's usually included in the loss function (e.g., nn.CrossEntropyLoss)\n",
    "\n",
    "    def forward(self, input_embeddings):\n",
    "        # Map embeddings to logits for each token in the vocabulary\n",
    "        logits = self.linear(input_embeddings)\n",
    "        return logits\n",
    "\n",
    "class CODEFUSIONModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, t5_model_name='t5-medium', d_model=512, nhead=8, num_layers=6):\n",
    "        super(CODEFUSIONModel, self).__init__()\n",
    "        self.t5_encoder = T5EncoderBlock(t5_model_name)\n",
    "        self.denoiser = Denoiser(d_model, nhead, num_layers)  # Updated Denoiser\n",
    "        self.decoder = DecoderWithCrossAttention(d_model, nhead, num_layers)  # Updated Decoder\n",
    "        self.classification_head = ClassificationHead(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, noisy_code_embeddings, input_ids, attention_mask=None):\n",
    "        # Encode natural language utterance\n",
    "        encoded_utterance = self.t5_encoder(input_ids, attention_mask)\n",
    "\n",
    "        # Process noisy code embeddings through denoiser with cross-attention to the encoded utterance\n",
    "        denoised_embeddings = self.denoiser(noisy_code_embeddings, encoded_utterance)\n",
    "\n",
    "        # Process denoised embeddings through decoder with cross-attention to the encoded utterance\n",
    "        decoded_embeddings = self.decoder(denoised_embeddings, encoded_utterance)\n",
    "\n",
    "        # Generate logits for each code token position\n",
    "        logits = self.classification_head(decoded_embeddings)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "def compute_loss(predicted_noise, actual_noise, denoised_embeddings, original_embeddings, logits, target_tokens):\n",
    "    # Noise Prediction Loss\n",
    "    noise_loss = torch.norm(predicted_noise - actual_noise, p=2)\n",
    "    print(f\"Noise loss computed: {noise_loss.item()}\")\n",
    "\n",
    "    # Embedding Fidelity Loss\n",
    "    embedding_loss = torch.norm(denoised_embeddings - original_embeddings, p=2)\n",
    "    print(f\"Embedding loss computed: {embedding_loss.item()}\")\n",
    "\n",
    "    # Token Prediction Loss with Padding Ignored\n",
    "    pad_token_id = t5_tokenizer.pad_token_id  # Ensure this is correctly set\n",
    "    ce_loss_fn = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "\n",
    "    # Debug: Print shapes and pad token ID\n",
    "    print(f\"Logits shape: {logits.shape}, Target tokens shape: {target_tokens.shape}, Pad token ID: {pad_token_id}\")\n",
    "\n",
    "    # Ensure logits are reshaped correctly for CrossEntropyLoss\n",
    "    logits_reshaped = logits.view(-1, logits.size(-1))\n",
    "    target_tokens_reshaped = target_tokens.view(-1)\n",
    "\n",
    "    # Debug: Print reshaped logits and target tokens shapes\n",
    "    print(f\"Reshaped logits shape: {logits_reshaped.shape}, Reshaped target tokens shape: {target_tokens_reshaped.shape}\")\n",
    "\n",
    "    # Debug: Check if any target token is out of bounds\n",
    "    max_logit_index = logits.size(-1) - 1\n",
    "    max_target_token = target_tokens_reshaped.max().item()\n",
    "    print(f\"Max logit index (vocab size - 1): {max_logit_index}, Max target token index: {max_target_token}\")\n",
    "\n",
    "    # Ensure no target token index exceeds the model's vocabulary size\n",
    "    if max_target_token > max_logit_index:\n",
    "        print(\"Error: Target token index exceeds the model's vocabulary size.\")\n",
    "\n",
    "    # Compute the CrossEntropyLoss\n",
    "    ce_loss = ce_loss_fn(logits_reshaped, target_tokens_reshaped)\n",
    "    print(f\"CrossEntropy loss computed: {ce_loss.item()}\")\n",
    "\n",
    "    # Combine losses\n",
    "    total_loss = noise_loss + embedding_loss + ce_loss\n",
    "    print(f\"Total loss computed: {total_loss.item()}\")\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def square_root_noise_schedule(t, total_steps=1200, max_noise=0.1):\n",
    "    \"\"\"\n",
    "    Calculates the noise level for a given step t using a square root schedule.\n",
    "    \n",
    "    Parameters:\n",
    "    - t: Current diffusion step (0 <= t < total_steps).\n",
    "    - total_steps: Total number of diffusion steps.\n",
    "    - max_noise: Maximum noise level at the final step.\n",
    "    \n",
    "    Returns:\n",
    "    - noise_level: Noise level at step t.\n",
    "    \"\"\"\n",
    "    # Normalize the current step to a range between 0 and 1\n",
    "    step_fraction = t / total_steps\n",
    "    # Calculate the noise level using a square root schedule\n",
    "    noise_level = max_noise * np.sqrt(step_fraction)\n",
    "    return noise_level"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "\n",
    "# Initialize the T5 tokenizer and model\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('google-t5/t5-small')\n",
    "t5_model = T5EncoderModel.from_pretrained('google-t5/t5-small')\n",
    "\n",
    "# Initialize Denoiser and Decoder with specified parameters\n",
    "hidden_dim = 512  # Hidden dimension size\n",
    "denoiser = Denoiser(d_model=hidden_dim, nhead=8, num_layers=10)\n",
    "decoder = DecoderWithCrossAttention(d_model=hidden_dim, nhead=8, num_layers=6)\n",
    "code_embedding_layer = CodeEmbeddingLayer(vocab_size=t5_tokenizer.vocab_size, embedding_dim=512)\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optim.AdamW(list(denoiser.parameters()) + list(decoder.parameters()), lr=5e-4, weight_decay=0)\n",
    "\n",
    "# Define the path to your dataset\n",
    "dataset_path = '/kaggle/input/pretraining-codefusion/PythonSnippets.txt'  # Update this path\n",
    "\n",
    "# Training loop\\\n",
    "num_diffusion_steps = 1200\n",
    "num_epochs = 10  # Specify the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    with open(dataset_path, 'r') as file:\n",
    "        for code_snippet in file:\n",
    "            optimizer.zero_grad()\n",
    "            code_snippet = code_snippet.rstrip('\\n')\n",
    "            tokens = t5_tokenizer.encode(code_snippet, return_tensors=\"pt\", add_special_tokens=True, max_length=128, truncation=True, padding=\"max_length\")\n",
    "            \n",
    "            embeddings = code_embedding_layer(tokens.to(torch.int64))\n",
    "\n",
    "            total_loss = 0\n",
    "\n",
    "            for t in range(num_diffusion_steps):\n",
    "                noise_level = square_root_noise_schedule(t)\n",
    "                noisy_embeddings = embeddings + torch.randn_like(embeddings) * noise_level\n",
    "                \n",
    "                # Pass the current timestep `t` to the Denoiser\n",
    "                denoised_embeddings, predicted_noise = denoiser(noisy_embeddings, t=t)  # Adjusted to include timestep `t`\n",
    "                \n",
    "                decoded_embeddings = decoder(denoised_embeddings)\n",
    "\n",
    "                noise_loss = torch.norm(predicted_noise - (noisy_embeddings - embeddings), p=2)\n",
    "                embedding_loss = torch.norm(decoded_embeddings - embeddings, p=2)\n",
    "                step_loss = noise_loss + embedding_loss\n",
    "\n",
    "                total_loss += step_loss\n",
    "\n",
    "            total_loss /= num_diffusion_steps\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f\"Epoch {epoch}, Avg Loss: {total_loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e018f7a6fa416bbc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward=2048, dropout=0.1):\n",
    "        super(Denoiser, self).__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, \n",
    "                                                   dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        # src shape: [seq_length, batch_size, d_model]\n",
    "        # src_mask and src_key_padding_mask are optional and can be used to mask out certain parts of the input\n",
    "        output = self.transformer_encoder(src, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        return output\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers=1, dim_feedforward=2048, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Transformer decoder layer\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward, \n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, tgt, memory):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tgt: The sequence to the decoder (denoised embeddings).\n",
    "            memory: The sequence from the last layer of the encoder (for pre-training, this could be Gaussian noise or another form of representation).\n",
    "        \"\"\"\n",
    "        # tgt and memory shapes: [seq_length, batch_size, d_model]\n",
    "        output = self.transformer_decoder(tgt, memory)\n",
    "        return output\n",
    "    \n",
    "tasks = ['unsupervised_code_generation', 'cpd']\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for code_snippet in code_corpus:\n",
    "        # Randomly select a task for this iteration\n",
    "        task = random.choice(tasks)\n",
    "\n",
    "        # Convert code_snippet to embeddings\n",
    "        # Note: Assuming code_embedding_layer can handle raw code snippets directly\n",
    "        code_embeddings = code_embedding_layer(code_snippet)\n",
    "\n",
    "        if task == 'unsupervised_code_generation':\n",
    "            # For unsupervised code generation, start with Gaussian noise\n",
    "            # Assuming the shape of code_embeddings is suitable for adding Gaussian noise directly\n",
    "            noisy_embeddings = add_gaussian_noise(code_embeddings)\n",
    "        elif task == 'cpd':\n",
    "            # For the CPD task, mask tokens in the code snippet and then convert to embeddings\n",
    "            masked_code_snippet = mask_tokens(code_snippet, language='python')  # Specify the language as needed\n",
    "            # Convert masked code snippet to embeddings and add Gaussian noise\n",
    "            noisy_embeddings = add_gaussian_noise(code_embedding_layer(masked_code_snippet))\n",
    "\n",
    "        # Denoising step\n",
    "        denoised_embeddings = denoiser(noisy_embeddings)\n",
    "\n",
    "        # Decoding step\n",
    "        decoded_embeddings = decoder(denoised_embeddings)\n",
    "\n",
    "        # Calculate loss\n",
    "        # You'll need to define compute_loss based on the task and expected output\n",
    "        # For CPD, the loss might involve comparing decoded embeddings to original (unmasked) embeddings\n",
    "        # For unsupervised code generation, the loss might involve the fidelity of generated code to valid code structures\n",
    "        #TODO: Make the compute loss as per the paper\n",
    "        loss = compute_loss(decoded_embeddings, code_embeddings, task=task)\n",
    "\n",
    "        # Backpropagate and update model parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18be99156c381242"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
