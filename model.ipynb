{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import T5EncoderModel\n",
    "import keyword\n",
    "import tokenize\n",
    "from io import StringIO\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def mask_tokens(code_snippet, language='python', mask_rate=0.15):\n",
    "    masked_code = []\n",
    "    if language == 'python':\n",
    "        # Tokenize the Python code snippet\n",
    "        tokens = list(tokenize.tokenize(StringIO(code_snippet).readline))\n",
    "        for tok in tokens:\n",
    "            # For keywords and identifiers (NAME tokens that aren't built-in functions), mask them based on mask_rate\n",
    "            if (tok.type == tokenize.NAME and (keyword.iskeyword(tok.string) or not tok.string.startswith('__'))) and random.random() < mask_rate:\n",
    "                masked_code.append('<MASK>')\n",
    "            else:\n",
    "                masked_code.append(tok.string)\n",
    "    elif language == 'bash':\n",
    "        # This is a placeholder: you'll need a more sophisticated method for Bash, possibly using regex\n",
    "        bash_keywords = ['if', 'else', 'fi', 'do', 'done', 'for', 'in', 'while', 'case', 'esac', 'echo', 'printf', 'export']\n",
    "        for word in code_snippet.split():\n",
    "            if word in bash_keywords and random.random() < mask_rate:\n",
    "                masked_code.append('<MASK>')\n",
    "            else:\n",
    "                masked_code.append(word)\n",
    "    return ' '.join(masked_code)\n",
    "\n",
    "\n",
    "def add_gaussian_noise(embeddings, mean=0.0, std=0.1):\n",
    "    noise = torch.randn_like(embeddings) * std + mean\n",
    "    return embeddings + noise\n",
    "    \n",
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward=2048, dropout=0.1):\n",
    "        super(Denoiser, self).__init__()\n",
    "        self.self_attn_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, \n",
    "                                       dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.cross_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.noise_prediction_layer = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, noisy_embeddings, encoded_utterance, t, src_key_padding_mask=None):\n",
    "        # Generate sinusoidal encoding for t\n",
    "        t_embed = self.sinusoidal_encoding(t, noisy_embeddings.size(-1)).to(noisy_embeddings.device)\n",
    "        # Add an extra dimension to make t_embed broadcastable to noisy_embeddings\n",
    "        t_embed = t_embed.unsqueeze(1)\n",
    "    \n",
    "        # Add the timestep embedding to the noisy embeddings\n",
    "        noisy_embeddings += t_embed\n",
    "\n",
    "        # Self-attention layers\n",
    "        for layer in self.self_attn_layers:\n",
    "            noisy_embeddings = layer(noisy_embeddings, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # Cross-attention layer\n",
    "        attn_output, _ = self.cross_attn(noisy_embeddings, encoded_utterance, encoded_utterance)\n",
    "\n",
    "        # Predict noise\n",
    "        predicted_noise = self.noise_prediction_layer(attn_output)\n",
    "\n",
    "        # Remove predicted noise to get denoised embeddings\n",
    "        denoised_embeddings = attn_output - predicted_noise\n",
    "\n",
    "        return denoised_embeddings, predicted_noise\n",
    "\n",
    "    def sinusoidal_encoding(self, t, d_model):\n",
    "        \"\"\"\n",
    "        Generates sinusoidal encodings for the timestep t.\n",
    "        \n",
    "        Parameters:\n",
    "        - t: Current timestep, a scalar.\n",
    "        - d_model: The dimension of the embeddings/model.\n",
    "        \n",
    "        Returns:\n",
    "        - Sinusoidal encoding for t with shape [1, d_model].\n",
    "        \"\"\"\n",
    "        position = torch.tensor([[t]], dtype=torch.float32)  # Shape: [1, 1]\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * -(math.log(10000.0) / d_model))\n",
    "        sinusoidal_embedding = torch.zeros(1, d_model)\n",
    "        sinusoidal_embedding[:, 0::2] = torch.sin(position * div_term)\n",
    "        sinusoidal_embedding[:, 1::2] = torch.cos(position * div_term)\n",
    "        return sinusoidal_embedding\n",
    "\n",
    "\n",
    "class DecoderWithCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers=1, dim_feedforward=2048, dropout=0.1):\n",
    "        super(DecoderWithCrossAttention, self).__init__()\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, \n",
    "                                                   dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, denoised_embeddings, encoded_utterance):\n",
    "        # Cross-attention in the decoder\n",
    "        # Note: denoised_embeddings is the target (tgt) and encoded_utterance is the memory input for cross-attention\n",
    "        output = self.transformer_decoder(denoised_embeddings, encoded_utterance)\n",
    "        return output\n",
    "\n",
    "\n",
    "class CodeEmbeddingLayer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CodeEmbeddingLayer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, code_tokens):\n",
    "        # Convert code tokens to embeddings\n",
    "        return self.embedding(code_tokens)\n",
    "\n",
    "class T5EncoderBlock(nn.Module):\n",
    "    def __init__(self, model_name='t5-medium'):\n",
    "        super(T5EncoderBlock, self).__init__()\n",
    "        self.encoder = T5EncoderModel.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # Process input tokens through the T5 encoder\n",
    "        encoder_outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return encoder_outputs.last_hidden_state\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, vocab_size):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, vocab_size)\n",
    "        # Note: Softmax is not applied here as it's usually included in the loss function (e.g., nn.CrossEntropyLoss)\n",
    "\n",
    "    def forward(self, input_embeddings):\n",
    "        # Map embeddings to logits for each token in the vocabulary\n",
    "        logits = self.linear(input_embeddings)\n",
    "        return logits\n",
    "\n",
    "class CODEFUSIONModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, denoiser, decoder,t5_model_name='t5-small'):\n",
    "        super(CODEFUSIONModel, self).__init__()\n",
    "        self.t5_encoder = T5EncoderBlock(t5_model_name)\n",
    "        self.denoiser = denoiser # Updated Denoiser\n",
    "        self.decoder = decoder  # Updated Decoder\n",
    "        self.classification_head = ClassificationHead(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, embeddings, input_ids, timesteps=1200, attention_mask=None):\n",
    "        # Encode natural language utterance\n",
    "        encoded_utterance = self.t5_encoder(input_ids, attention_mask)\n",
    "\n",
    "        for t in range(timesteps):\n",
    "            gaussian_noise = torch.randn_like(embeddings) * square_root_noise_schedule(t)\n",
    "            noisy_embeddings = embeddings + gaussian_noise\n",
    "        \n",
    "            # Pass noisy embeddings through denoiser\n",
    "            denoised_embeddings, predicted_noise = model.denoiser(noisy_embeddings, encoded_utterance, t)\n",
    "\n",
    "        # Process denoised embeddings through decoder with cross-attention to the encoded utterance\n",
    "        decoded_embeddings = self.decoder(denoised_embeddings, encoded_utterance)\n",
    "\n",
    "        # Generate logits for each code token position\n",
    "        logits = self.classification_head(decoded_embeddings)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def compute_loss(predicted_noise, actual_noise, denoised_embeddings, original_embeddings, logits, target_tokens):\n",
    "    # Noise Prediction Loss\n",
    "    noise_loss = torch.norm(predicted_noise - actual_noise, p=2)\n",
    "\n",
    "    # Embedding Fidelity Loss\n",
    "    embedding_loss = torch.norm(denoised_embeddings - original_embeddings, p=2)\n",
    "\n",
    "    # Token Prediction Loss with Padding Ignored\n",
    "    pad_token_id = t5_tokenizer.pad_token_id  # Get padding token ID\n",
    "    ce_loss_fn = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "    ce_loss = ce_loss_fn(logits.view(-1, logits.size(-1)), target_tokens.view(-1))\n",
    "\n",
    "    # Combine losses\n",
    "    total_loss = noise_loss + embedding_loss + ce_loss\n",
    "    return total_loss\n",
    "\n",
    "def square_root_noise_schedule(t, total_steps=1200, max_noise=1):\n",
    "    \"\"\"\n",
    "    Calculates the noise level for a given step t using a square root schedule.\n",
    "    \n",
    "    Parameters:\n",
    "    - t: Current diffusion step (0 <= t < total_steps).\n",
    "    - total_steps: Total number of diffusion steps.\n",
    "    - max_noise: Maximum noise level at the final step.\n",
    "    \n",
    "    Returns:\n",
    "    - noise_level: Noise level at step t.\n",
    "    \"\"\"\n",
    "    # Normalize the current step to a range between 0 and 1\n",
    "    step_fraction = t / total_steps\n",
    "    # Calculate the noise level using a square root schedule\n",
    "    noise_level = max_noise * np.sqrt(step_fraction)\n",
    "    return noise_level"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "\n",
    "embedding_dim = 512\n",
    "dataset_path = 'PythonSnippets.txt'\n",
    "vocab_size = 32000\n",
    "batch_size = 64\n",
    "\n",
    "# Initialize the T5 tokenizer and model from CodeT5\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('google-t5/t5-small')\n",
    "t5_model = T5EncoderModel.from_pretrained('google-t5/t5-small')\n",
    "\n",
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, filepath, tokenizer, max_length=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            self.data = file.read().strip().split('\\n\\n')\n",
    "        \n",
    "        # Calculate the length of each code snippet before tokenization and truncation\n",
    "        self.lengths = [len(snippet) for snippet in self.data]\n",
    "        \n",
    "        # Calculate weights based on the lengths, bias towards longer snippets\n",
    "        self.weights = [len(snippet)**0.5 for snippet in self.data]  # Square root to not overweight too much on longer snippets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        code_snippet = self.data[idx]\n",
    "        tokens = self.tokenizer.encode_plus(\n",
    "            code_snippet,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return tokens.input_ids.squeeze(0), tokens.attention_mask.squeeze(0)\n",
    "\n",
    "dataset = CodeDataset(dataset_path, t5_tokenizer)\n",
    "sampler = WeightedRandomSampler(weights=dataset.weights, num_samples=80000, replacement=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e018f7a6fa416bbc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import wandb\n",
    "\n",
    "api_key = 'b40ad50fa130d6cc3b93e2c9a351630003a74dc6'\n",
    "\n",
    "# Log in to wandb\n",
    "wandb.login(key=api_key)\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project='experiments')\n",
    "\n",
    "\n",
    "# Training loop\n",
    "# Initialize models, and optimizer\n",
    "embedding_layer = CodeEmbeddingLayer(vocab_size, embedding_dim).cuda()\n",
    "denoiser = Denoiser(d_model=embedding_dim, nhead=8, num_layers=10).cuda()\n",
    "decoder = DecoderWithCrossAttention(d_model=embedding_dim, nhead=8, num_layers=6).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    list(embedding_layer.parameters()) +\n",
    "    list(denoiser.parameters()) +\n",
    "    list(decoder.parameters()), lr=5e-4, weight_decay=0\n",
    ")\n",
    "\n",
    "batch_size = 64  # Adjust as needed\n",
    "\n",
    "# Start of the training loop\n",
    "num_epochs = 1\n",
    "# Initialize the GradScaler for dynamic scaling\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    for batch_index, (input_ids, _) in enumerate(loop):\n",
    "        start_time = time.time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = input_ids.cuda()\n",
    "\n",
    "        with autocast():  # Enable automatic mixed precision\n",
    "            embeddings = embedding_layer(input_ids)\n",
    "\n",
    "            total_diffusion_time = 0\n",
    "            for t in range(1200):\n",
    "                gaussian_noise = torch.randn_like(embeddings) * square_root_noise_schedule(t)\n",
    "                noisy_embeddings = embeddings + gaussian_noise\n",
    "\n",
    "                assert gaussian_noise.is_cuda, \"Gaussian noise not on GPU\"\n",
    "                assert noisy_embeddings.is_cuda, \"Noisy embeddings not on GPU\"\n",
    "\n",
    "                denoised_embeddings, predicted_noise = denoiser(noisy_embeddings, gaussian_noise, t)\n",
    "\n",
    "            decoded_embeddings = decoder(denoised_embeddings, denoised_embeddings)\n",
    "            loss = F.mse_loss(decoded_embeddings, embeddings)\n",
    "\n",
    "        # Scale the loss and call backward() to create scaled gradients\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscales the gradients and calls or skips optimizer.step()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        # Updates the scale for next iteration\n",
    "        scaler.update()\n",
    "\n",
    "        loop.set_description(f'Epoch [{epoch}/{num_epochs}]')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        wandb.log({\"loss\": loss.item()})\n",
    "        \n",
    "        total_loop_time = time.time() - start_time\n",
    "        print(f\"Batch {batch_index}: Total iteration time: {total_loop_time:.3f}s\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b39aa6d58db1793d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CODEFUSIONDataset(Dataset):\n",
    "    def __init__(self, utterances, code_snippets, tokenizer):\n",
    "        self.utterances = utterances\n",
    "        self.code_snippets = code_snippets\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.utterances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        utterance = self.utterances[idx]\n",
    "        code_snippet = self.code_snippets[idx]\n",
    "\n",
    "        # Tokenize utterance and code snippet\n",
    "        utterance_tokens = self.tokenizer(utterance, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        code_snippet_tokens = self.tokenizer(code_snippet, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "\n",
    "        return utterance_tokens, code_snippet_tokens\n",
    "\n",
    "# Assuming `utterances` and `code_snippets` are lists containing your dataset\n",
    "# and `tokenizer` is your pre-initialized tokenizer\n",
    "dataset = CODEFUSIONDataset(utterances, code_snippets, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d3898d567f4949e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embedding_layer = CodeEmbeddingLayer(vocab_size, embedding_dim).cuda()\n",
    "denoiser = Denoiser(d_model=embedding_dim, nhead=8, num_layers=10).cuda()\n",
    "decoder = DecoderWithCrossAttention(d_model=embedding_dim, nhead=8, num_layers=6).cuda()\n",
    "\n",
    "embedding_layer.load_state_dict(torch.load(embedding_layer_checkpoint))\n",
    "denoiser.load_state_dict(torch.load(denoiser_checkpoint))\n",
    "decoder.load_state_dict(torch.load(decoder_checkpoint))\n",
    "\n",
    "model = CODEFUSIONModel(embedding_dim=512, vocab_size=tokenizer.vocab_size, denoiser=denoiser, decoder=decoder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "608a2ea86d382d9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
